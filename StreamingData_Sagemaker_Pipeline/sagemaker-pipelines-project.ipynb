{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orchestrating Jobs, Model Registration, and Continuous Deployment with Amazon SageMaker\n",
    "\n",
    "Amazon SageMaker offers Machine Learning application developers and Machine Learning operations engineers the ability to orchestrate SageMaker jobs and author reproducible Machine Learning pipelines, deploy custom-build models for inference in real-time with low latency or offline inferences with Batch Transform, and track lineage of artifacts. You can institute sound operational practices in deploying and monitoring production workflows, deployment of model artifacts, and track artifact lineage through a simple interface, adhering to safety and best-practice paradigmsfor Machine Learning application development.\n",
    "\n",
    "The SageMaker Pipelines service supports a SageMaker Machine Learning Pipeline Domain Specific Language (DSL), which is a declarative Json specification. This DSL defines a Directed Acyclic Graph (DAG) of pipeline parameters and SageMaker job steps. The SageMaker Python Software Developer Kit (SDK) streamlines the generation of the pipeline DSL using constructs that are already familiar to engineers and scientists alike.\n",
    "\n",
    "The SageMaker Model Registry is where trained models are stored, versioned, and managed. Data Scientists and Machine Learning Engineers can compare model versions, approve models for deployment, and deploy models from different AWS accounts, all from a single Model Registry. SageMaker enables customers to follow the best practices with ML Ops and getting started right. Customers are able to standup a full ML Ops end-to-end system with a single API call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Pipelines\n",
    "\n",
    "Amazon SageMaker Pipelines support the following activites:\n",
    "\n",
    "* Pipelines - A Directed Acyclic Graph of steps and conditions to orchestrate SageMaker jobs and resource creation.\n",
    "* Processing Job steps - A simplified, managed experience on SageMaker to run data processing workloads, such as feature engineering, data validation, model evaluation, and model interpretation.\n",
    "* Training Job steps - An iterative process that teaches a model to make predictions by presenting examples from a training dataset.\n",
    "* Conditional step execution - Provides conditional execution of branches in a pipeline.\n",
    "* Registering Models - Creates a model package resource in the Model Registry that can be used to create deployable models in Amazon SageMaker.\n",
    "* Creating Model steps - Create a model for use in transform steps or later publication as an endpoint.\n",
    "* Parameterized Pipeline executions - Allows pipeline executions to vary by supplied parameters.\n",
    "* Transform Job steps - A batch transform to preprocess datasets to remove noise or bias that interferes with training or inference from your dataset, get inferences from large datasets, and run inference when you don't need a persistent endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layout of the SageMaker ModelBuild Project Template\n",
    "\n",
    "The template provides a starting point for bringing your SageMaker Pipeline development to production.\n",
    "\n",
    "```\n",
    "|-- codebuild-buildspec.yml\n",
    "|-- CONTRIBUTING.md\n",
    "|-- pipelines\n",
    "|   |-- abalone\n",
    "|   |   |-- evaluate.py\n",
    "|   |   |-- __init__.py\n",
    "|   |   |-- pipeline.py\n",
    "|   |   `-- preprocess.py\n",
    "|   |-- get_pipeline_definition.py\n",
    "|   |-- __init__.py\n",
    "|   |-- run_pipeline.py\n",
    "|   |-- _utils.py\n",
    "|   `-- __version__.py\n",
    "|-- README.md\n",
    "|-- sagemaker-pipelines-project.ipynb\n",
    "|-- setup.cfg\n",
    "|-- setup.py\n",
    "|-- tests\n",
    "|   `-- test_pipelines.py\n",
    "`-- tox.ini\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A description of some of the artifacts is provided below:\n",
    "<br/><br/>\n",
    "Your codebuild execution instructions:\n",
    "```\n",
    "|-- codebuild-buildspec.yml\n",
    "```\n",
    "<br/><br/>\n",
    "Your pipeline artifacts, which includes a pipeline module defining the required `get_pipeline` method that returns an instance of a SageMaker pipeline, a preprocessing script that is used in feature engineering, and a model evaluation script to measure the Mean Squared Error of the model that's trained by the pipeline:\n",
    "\n",
    "```\n",
    "|-- pipelines\n",
    "|   |-- abalone\n",
    "|   |   |-- evaluate.py\n",
    "|   |   |-- __init__.py\n",
    "|   |   |-- pipeline.py\n",
    "|   |   `-- preprocess.py\n",
    "\n",
    "```\n",
    "\n",
    "For additional subfolders with code and/or artifacts needed by pipeline, they need to be packaged correctly by the `setup.py` file. For example, to package a `pipelines/source` folder,\n",
    "\n",
    "* Include a `__init__.py` file within the `source` folder.\n",
    "* Add it to the `setup.py` file's `package_data` like so:\n",
    "\n",
    "```\n",
    "...\n",
    "    packages=setuptools.find_packages(),\n",
    "    include_package_data=True,\n",
    "    package_data={\"pipelines.my_pipeline.src\": [\"*.txt\"]},\n",
    "    python_requires=\">=3.6\",\n",
    "    install_requires=required_packages,\n",
    "    extras_require=extras,\n",
    "...\n",
    "```\n",
    "\n",
    "<br/><br/>\n",
    "Utility modules for getting pipeline definition jsons and running pipelines:\n",
    "\n",
    "```\n",
    "|-- pipelines\n",
    "|   |-- get_pipeline_definition.py\n",
    "|   |-- __init__.py\n",
    "|   |-- run_pipeline.py\n",
    "|   |-- _utils.py\n",
    "|   `-- __version__.py\n",
    "```\n",
    "<br/><br/>\n",
    "Python package artifacts:\n",
    "```\n",
    "|-- setup.cfg\n",
    "|-- setup.py\n",
    "```\n",
    "<br/><br/>\n",
    "A stubbed testing module for testing your pipeline as you develop:\n",
    "```\n",
    "|-- tests\n",
    "|   `-- test_pipelines.py\n",
    "```\n",
    "<br/><br/>\n",
    "The `tox` testing framework configuration:\n",
    "```\n",
    "`-- tox.ini\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A SageMaker Pipeline\n",
    "\n",
    "The pipeline that we create follows a typical Machine Learning Application pattern of pre-processing, training, evaluation, and conditional model registration and publication, if the quality of the model is sufficient.\n",
    "\n",
    "![A typical ML Application pipeline](img/pipeline-full.png)\n",
    "\n",
    "### Getting some constants\n",
    "\n",
    "We get some constants from the local execution environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:332: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n",
      "INFO:sagemaker.processing:Uploaded None to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/5ff1e977981a849925788a27ce29face/sourcedir.tar.gz\n",
      "Uploaded None to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/5ff1e977981a849925788a27ce29face/sourcedir.tar.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/a7904ce4f08d9c1d2b41073f1bedb751/runproc.sh\n",
      "runproc.sh uploaded to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/a7904ce4f08d9c1d2b41073f1bedb751/runproc.sh\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.processing:Uploaded None to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/df74d0b6f0a1b4ce91793f6c5facf1c9/sourcedir.tar.gz\n",
      "Uploaded None to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/df74d0b6f0a1b4ce91793f6c5facf1c9/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/d4ac4332fb627ef802e2fdbb9c4f4f73/runproc.sh\n",
      "runproc.sh uploaded to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/d4ac4332fb627ef802e2fdbb9c4f4f73/runproc.sh\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "INFO:sagemaker.processing:Uploaded None to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/7be0d471eb09754e3cf4fbff1648e670/sourcedir.tar.gz\n",
      "Uploaded None to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/7be0d471eb09754e3cf4fbff1648e670/sourcedir.tar.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/5e6365100517b111feeee622b9f5bf1e/runproc.sh\n",
      "runproc.sh uploaded to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/5e6365100517b111feeee622b9f5bf1e/runproc.sh\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "INFO:sagemaker.processing:Uploaded None to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/5c982794da01a450adacebbc538e2e5f/sourcedir.tar.gz\n",
      "Uploaded None to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/5c982794da01a450adacebbc538e2e5f/sourcedir.tar.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/28b75a1d29c043327346b83c2c52a77a/runproc.sh\n",
      "runproc.sh uploaded to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/28b75a1d29c043327346b83c2c52a77a/runproc.sh\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "INFO:sagemaker.processing:Uploaded None to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/2f44fc39cfee864747c1f25b5f3aa2ab/sourcedir.tar.gz\n",
      "Uploaded None to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/2f44fc39cfee864747c1f25b5f3aa2ab/sourcedir.tar.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/3d6ad20c15768360c5fe70fa3e16a047/runproc.sh\n",
      "runproc.sh uploaded to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/3d6ad20c15768360c5fe70fa3e16a047/runproc.sh\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "INFO:sagemaker.processing:Uploaded None to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/cd508c544191fe46c8c23616bdeb3bcc/sourcedir.tar.gz\n",
      "Uploaded None to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/cd508c544191fe46c8c23616bdeb3bcc/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/32a82c92f83a9e4230282a2e842f3bbd/runproc.sh\n",
      "runproc.sh uploaded to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/32a82c92f83a9e4230282a2e842f3bbd/runproc.sh\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "INFO:sagemaker.processing:Uploaded None to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/b774ebf84a79e3ec191c40f362e52e44/sourcedir.tar.gz\n",
      "Uploaded None to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/b774ebf84a79e3ec191c40f362e52e44/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/46faab293ab3562c0d0ba452db733ded/runproc.sh\n",
      "runproc.sh uploaded to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/46faab293ab3562c0d0ba452db733ded/runproc.sh\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "INFO:sagemaker.processing:Uploaded None to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/ed222470bcf28b19c144d65f9468e8de/sourcedir.tar.gz\n",
      "Uploaded None to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/ed222470bcf28b19c144d65f9468e8de/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/6756218c912c78a2e0c340de46e98658/runproc.sh\n",
      "runproc.sh uploaded to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/6756218c912c78a2e0c340de46e98658/runproc.sh\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.processing:Uploaded None to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/b774ebf84a79e3ec191c40f362e52e44/sourcedir.tar.gz\n",
      "Uploaded None to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/b774ebf84a79e3ec191c40f362e52e44/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/46faab293ab3562c0d0ba452db733ded/runproc.sh\n",
      "runproc.sh uploaded to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/46faab293ab3562c0d0ba452db733ded/runproc.sh\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.processing:Uploaded None to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/5241cd89f9f92a8957b8a70635fdbd47/sourcedir.tar.gz\n",
      "Uploaded None to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/5241cd89f9f92a8957b8a70635fdbd47/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/a16f3a60cbae5bf7e273a2547cc8a6bc/runproc.sh\n",
      "runproc.sh uploaded to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/a16f3a60cbae5bf7e273a2547cc8a6bc/runproc.sh\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.processing:Uploaded None to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/5ff1e977981a849925788a27ce29face/sourcedir.tar.gz\n",
      "Uploaded None to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/5ff1e977981a849925788a27ce29face/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/a7904ce4f08d9c1d2b41073f1bedb751/runproc.sh\n",
      "runproc.sh uploaded to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/a7904ce4f08d9c1d2b41073f1bedb751/runproc.sh\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "INFO:sagemaker.processing:Uploaded None to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/df74d0b6f0a1b4ce91793f6c5facf1c9/sourcedir.tar.gz\n",
      "Uploaded None to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/df74d0b6f0a1b4ce91793f6c5facf1c9/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/d4ac4332fb627ef802e2fdbb9c4f4f73/runproc.sh\n",
      "runproc.sh uploaded to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/d4ac4332fb627ef802e2fdbb9c4f4f73/runproc.sh\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n",
      "Using provided s3_resource\n",
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.processing:Uploaded None to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/7be0d471eb09754e3cf4fbff1648e670/sourcedir.tar.gz\n",
      "Uploaded None to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/7be0d471eb09754e3cf4fbff1648e670/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/5e6365100517b111feeee622b9f5bf1e/runproc.sh\n",
      "runproc.sh uploaded to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/5e6365100517b111feeee622b9f5bf1e/runproc.sh\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "INFO:sagemaker.processing:Uploaded None to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/5c982794da01a450adacebbc538e2e5f/sourcedir.tar.gz\n",
      "Uploaded None to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/5c982794da01a450adacebbc538e2e5f/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/28b75a1d29c043327346b83c2c52a77a/runproc.sh\n",
      "runproc.sh uploaded to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/28b75a1d29c043327346b83c2c52a77a/runproc.sh\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "INFO:sagemaker.processing:Uploaded None to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/2f44fc39cfee864747c1f25b5f3aa2ab/sourcedir.tar.gz\n",
      "Uploaded None to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/2f44fc39cfee864747c1f25b5f3aa2ab/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/3d6ad20c15768360c5fe70fa3e16a047/runproc.sh\n",
      "runproc.sh uploaded to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/3d6ad20c15768360c5fe70fa3e16a047/runproc.sh\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n",
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "INFO:sagemaker.processing:Uploaded None to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/cd508c544191fe46c8c23616bdeb3bcc/sourcedir.tar.gz\n",
      "Uploaded None to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/cd508c544191fe46c8c23616bdeb3bcc/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/32a82c92f83a9e4230282a2e842f3bbd/runproc.sh\n",
      "runproc.sh uploaded to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/32a82c92f83a9e4230282a2e842f3bbd/runproc.sh\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "INFO:sagemaker.processing:Uploaded None to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/b774ebf84a79e3ec191c40f362e52e44/sourcedir.tar.gz\n",
      "Uploaded None to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/b774ebf84a79e3ec191c40f362e52e44/sourcedir.tar.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n",
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/46faab293ab3562c0d0ba452db733ded/runproc.sh\n",
      "runproc.sh uploaded to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/46faab293ab3562c0d0ba452db733ded/runproc.sh\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "INFO:sagemaker.processing:Uploaded None to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/ed222470bcf28b19c144d65f9468e8de/sourcedir.tar.gz\n",
      "Uploaded None to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/ed222470bcf28b19c144d65f9468e8de/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/6756218c912c78a2e0c340de46e98658/runproc.sh\n",
      "runproc.sh uploaded to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/6756218c912c78a2e0c340de46e98658/runproc.sh\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "INFO:sagemaker.processing:Uploaded None to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/b774ebf84a79e3ec191c40f362e52e44/sourcedir.tar.gz\n",
      "Uploaded None to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/b774ebf84a79e3ec191c40f362e52e44/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/46faab293ab3562c0d0ba452db733ded/runproc.sh\n",
      "runproc.sh uploaded to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/46faab293ab3562c0d0ba452db733ded/runproc.sh\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n",
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.processing:Uploaded None to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/5241cd89f9f92a8957b8a70635fdbd47/sourcedir.tar.gz\n",
      "Uploaded None to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/5241cd89f9f92a8957b8a70635fdbd47/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/a16f3a60cbae5bf7e273a2547cc8a6bc/runproc.sh\n",
      "runproc.sh uploaded to s3://truck-eta-classification/TruckETAClassification-StreamingDataPipeline/code/a16f3a60cbae5bf7e273a2547cc8a6bc/runproc.sh\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "ename": "WaiterError",
     "evalue": "Waiter PipelineExecutionComplete failed: Max attempts exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWaiterError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 34\u001b[0m\n\u001b[1;32m     30\u001b[0m execution \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m     32\u001b[0m execution\u001b[38;5;241m.\u001b[39mdescribe()\n\u001b[0;32m---> 34\u001b[0m \u001b[43mexecution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/workflow/pipeline.py:957\u001b[0m, in \u001b[0;36m_PipelineExecution.wait\u001b[0;34m(self, delay, max_attempts)\u001b[0m\n\u001b[1;32m    928\u001b[0m model \u001b[38;5;241m=\u001b[39m botocore\u001b[38;5;241m.\u001b[39mwaiter\u001b[38;5;241m.\u001b[39mWaiterModel(\n\u001b[1;32m    929\u001b[0m     {\n\u001b[1;32m    930\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    952\u001b[0m     }\n\u001b[1;32m    953\u001b[0m )\n\u001b[1;32m    954\u001b[0m waiter \u001b[38;5;241m=\u001b[39m botocore\u001b[38;5;241m.\u001b[39mwaiter\u001b[38;5;241m.\u001b[39mcreate_waiter_with_client(\n\u001b[1;32m    955\u001b[0m     waiter_id, model, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session\u001b[38;5;241m.\u001b[39msagemaker_client\n\u001b[1;32m    956\u001b[0m )\n\u001b[0;32m--> 957\u001b[0m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPipelineExecutionArn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/waiter.py:55\u001b[0m, in \u001b[0;36mcreate_waiter_with_client.<locals>.wait\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 55\u001b[0m     \u001b[43mWaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/waiter.py:388\u001b[0m, in \u001b[0;36mWaiter.wait\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m         reason \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    385\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMax attempts exceeded. Previously accepted state: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    386\u001b[0m             \u001b[38;5;241m%\u001b[39m (acceptor\u001b[38;5;241m.\u001b[39mexplanation)\n\u001b[1;32m    387\u001b[0m         )\n\u001b[0;32m--> 388\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WaiterError(\n\u001b[1;32m    389\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    390\u001b[0m         reason\u001b[38;5;241m=\u001b[39mreason,\n\u001b[1;32m    391\u001b[0m         last_response\u001b[38;5;241m=\u001b[39mresponse,\n\u001b[1;32m    392\u001b[0m     )\n\u001b[1;32m    393\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(sleep_amount)\n",
      "\u001b[0;31mWaiterError\u001b[0m: Waiter PipelineExecutionComplete failed: Max attempts exceeded"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "\n",
    "region = \"us-east-2\"\n",
    "role = \"arn:aws:iam::143176219551:role/service-role/AmazonSageMakerServiceCatalogProductsUseRole\"\n",
    "default_bucket = \"truck-eta-classification\"\n",
    "\n",
    "# Change these to reflect your project/business name or if you want to separate ModelPackageGroup/Pipeline from the rest of your team\n",
    "pipeline_name = \"TruckETAClassification-StreamingDataPipeline\"\n",
    "base_job_prefix = \"TruckETAClassification\"\n",
    "processing_instance_type = \"ml.m5.xlarge\"\n",
    "training_instance_type = \"ml.m5.xlarge\"\n",
    "\n",
    "from pipelines.abalone.pipeline import get_pipeline\n",
    "\n",
    "pipeline = get_pipeline(\n",
    "    region=region,\n",
    "    role=role,\n",
    "    default_bucket=default_bucket,\n",
    "    pipeline_name=pipeline_name,\n",
    "    base_job_prefix = base_job_prefix,\n",
    "    processing_instance_type = processing_instance_type,\n",
    "    training_instance_type = training_instance_type\n",
    ")\n",
    "\n",
    "\n",
    "pipeline.upsert(role_arn=role)\n",
    "\n",
    "execution = pipeline.start()\n",
    "\n",
    "execution.describe()\n",
    "\n",
    "execution.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the pipeline instance\n",
    "\n",
    "Here we get the pipeline instance from your pipeline module so that we can work with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipelines.abalone.pipeline import get_pipeline\n",
    "\n",
    "\n",
    "pipeline = get_pipeline(\n",
    "    region=region,\n",
    "    role=role,\n",
    "    default_bucket=default_bucket,\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    pipeline_name=pipeline_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit the pipeline to SageMaker and start execution\n",
    "\n",
    "Let's submit our pipeline definition to the workflow service. The role passed in will be used by the workflow service to create all the jobs defined in the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start the pipeline, accepting all the default parameters.\n",
    "\n",
    "Values can also be passed into these pipeline parameters on starting of the pipeline, and will be covered later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Operations: examining and waiting for pipeline execution\n",
    "\n",
    "Now we describe execution instance and list the steps in the execution to find out more about the execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can wait for the execution by invoking `wait()` on the execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can list the execution steps to check out the status and artifacts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameterized Executions\n",
    "\n",
    "We can run additional executions of the pipeline specifying different pipeline parameters. The parameters argument is a dictionary whose names are the parameter names, and whose values are the primitive values to use as overrides of the defaults.\n",
    "\n",
    "Of particular note, based on the performance of the model, we may want to kick off another pipeline execution, but this time on a compute-optimized instance type and set the model approval status automatically be \"Approved\". This means that the model package version generated by the `RegisterModel` step will automatically be ready for deployment through CI/CD pipelines, such as with SageMaker Projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start(\n",
    "    parameters=dict(\n",
    "        ProcessingInstanceType=\"ml.c5.xlarge\",\n",
    "        ModelApprovalStatus=\"Approved\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.list_steps()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
